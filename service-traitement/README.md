# ğŸ”„ Service de Traitement (service-traitement)

![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&logo=openjdk&logoColor=white)
![Spring](https://img.shields.io/badge/spring-%236DB33F.svg?style=for-the-badge&logo=spring&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/apache%20kafka-%23231F20.svg?style=for-the-badge&logo=apache-kafka&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/postgresql-%23316192.svg?style=for-the-badge&logo=postgresql&logoColor=white)

> ğŸ§  **CÅ“ur mÃ©tier du systÃ¨me BugTracker** - Responsable du traitement, de la persistance et de l'exposition des donnÃ©es de bugs. Il implÃ©mente un modÃ¨le Ã  double responsabilitÃ©, agissant Ã  la fois comme un **consommateur d'Ã©vÃ©nements** et comme un **fournisseur d'API REST**.

## ğŸ“‹ Table des MatiÃ¨res

- [ğŸ—ï¸ Architecture et RÃ´les](#ï¸-architecture-et-rÃ´les)
  - [ğŸ“¨ RÃ´le nÂ°1 : Consommateur d'Ã‰vÃ©nements](#-rÃ´le-n1--consommateur-dÃ©vÃ©nements)
  - [ğŸ”Œ RÃ´le nÂ°2 : Fournisseur d'API REST](#-rÃ´le-n2--fournisseur-dapi-rest)
- [ğŸ—„ï¸ Interaction avec la Base de DonnÃ©es](#ï¸-interaction-avec-la-base-de-donnÃ©es)
- [ğŸ“Š ModÃ¨le de DonnÃ©es](#-modÃ¨le-de-donnÃ©es)
- [ğŸ”Œ API Endpoints](#-api-endpoints)
  - [ğŸ“‹ GET /api/bugs](#-get-apibugs)
  - [ğŸ” GET /api/bugs/{id}](#-get-apibugsid)
- [âš™ï¸ Configuration](#ï¸-configuration)
- [ğŸ’» DÃ©veloppement](#-dÃ©veloppement)
  - [ğŸ“‹ PrÃ©requis](#-prÃ©requis)
  - [ğŸ”¨ Compilation](#-compilation)
  - [ğŸš€ Lancement et Tests](#-lancement-et-tests)

## ğŸ—ï¸ Architecture et RÃ´les

Ce service est un **composant central** qui relie le pipeline de donnÃ©es asynchrone Ã  l'accÃ¨s synchrone requis par les applications clientes (comme le frontend).

### ğŸ“¨ RÃ´le nÂ°1 : Consommateur d'Ã‰vÃ©nements

1. **ğŸ¯ Abonnement Ã  Kafka** : Le service s'abonne au topic Kafka `bugs.reported` en utilisant un `groupId` spÃ©cifique (`bug-processors`). Cela permet, Ã  l'avenir, de lancer plusieurs instances de ce service pour traiter les messages en parallÃ¨le et assurer la scalabilitÃ©

2. **âš™ï¸ Traitement des Messages** : Lorsqu'un message est reÃ§u de Kafka, le `BugConsumerService` le dÃ©sÃ©rialise depuis son format JSON

3. **ğŸ’¾ Persistance** : Il mappe ensuite les donnÃ©es de l'Ã©vÃ©nement Ã  l'entitÃ© JPA `BugReportEntity` et la sauvegarde dans la base de donnÃ©es PostgreSQL. C'est Ã  cette Ã©tape que l'Ã©vÃ©nement volatile devient un enregistrement de bug concret et permanent

### ğŸ”Œ RÃ´le nÂ°2 : Fournisseur d'API REST

1. **ğŸŒ Exposition d'Endpoints** : Le `BugReportController` expose une API REST CRUD (Create, Read, Update, Delete) pour la gestion des bugs. Dans ce prototype, les fonctions de lecture sont implÃ©mentÃ©es

2. **ğŸ–¥ï¸ Service pour le Frontend** : Ces endpoints sont la source de vÃ©ritÃ© pour toute interface utilisateur. Le frontend interrogera cette API (via la Gateway) pour afficher la liste des bugs, les dÃ©tails d'un bug spÃ©cifique, etc.

## ğŸ—„ï¸ Interaction avec la Base de DonnÃ©es

Ce service est le **seul composant** de l'architecture autorisÃ© Ã  Ã©crire et lire dans la table principale des bugs de la base de donnÃ©es PostgreSQL.

## ğŸ“Š ModÃ¨le de DonnÃ©es

L'entitÃ© principale est `BugReportEntity`, qui est mappÃ©e Ã  la table `bugs`. Pour stocker des donnÃ©es complexes et non structurÃ©es (comme les stack traces ou les contextes), ce service utilise des colonnes de type **JSONB** de PostgreSQL, grÃ¢ce Ã  la bibliothÃ¨que `hypersistence-utils`. 

> ğŸ’¡ Cela offre un excellent compromis entre la structure d'une base de donnÃ©es relationnelle et la flexibilitÃ© du NoSQL.

## ğŸ”Œ API Endpoints

### ğŸ“‹ GET /api/bugs

RÃ©cupÃ¨re une liste de tous les rapports de bugs stockÃ©s en base de donnÃ©es.

- **MÃ©thode** : `GET`
- **Chemin** : `/api/bugs`
- **RÃ©ponse** : Un tableau JSON d'objets `BugReportEntity`

```json
[
  {
    "id": 1,
    "projectKey": "PROJ-A",
    "level": "ERROR",
    "message": "Erreur de connexion Ã  la base",
    "..."
  },
  {
    "id": 2,
    "..."
  }
]
```

### ğŸ” GET /api/bugs/{id}

RÃ©cupÃ¨re les dÃ©tails d'un seul rapport de bug par son identifiant unique.

- **MÃ©thode** : `GET`
- **Chemin** : `/api/bugs/123` (oÃ¹ 123 est l'ID du bug)
- **RÃ©ponse en cas de succÃ¨s** : `200 OK` avec l'objet JSON `BugReportEntity` correspondant
- **RÃ©ponse si non trouvÃ©** : `404 Not Found`

## âš™ï¸ Configuration

La configuration du service se fait via `src/main/resources/application.properties` et peut Ãªtre surchargÃ©e par des variables d'environnement dans `docker-compose.yml`.

| PropriÃ©tÃ© | Variable d'Environnement Docker | Description |
|-----------|--------------------------------|-------------|
| `server.port` | (via ports dans Docker Compose) | Le port sur lequel le service Ã©coute. **DÃ©faut : 8082** |
| `spring.datasource.url` | `SPRING_DATASOURCE_URL` | L'URL de connexion JDBC Ã  la base PostgreSQL |
| `spring.datasource.username` | `SPRING_DATASOURCE_USERNAME` | L'utilisateur pour la connexion Ã  la base de donnÃ©es |
| `spring.datasource.password` | `SPRING_DATASOURCE_PASSWORD` | Le mot de passe pour la connexion |
| `spring.kafka.bootstrap-servers` | `SPRING_KAFKA_BOOTSTRAP_SERVERS` | L'adresse des brokers Kafka |
| `bugtracker.kafka-topic` | (configurable via env var) | Le nom du topic Kafka Ã  Ã©couter |

## ğŸ’» DÃ©veloppement

### ğŸ“‹ PrÃ©requis

- **â˜• JDK 17+**
- **ğŸ“¦ Maven 3.8+**
- **ğŸ‹ Docker & Docker Compose**

### ğŸ”¨ Compilation

Pour compiler le service, exÃ©cutez la commande suivante depuis le dossier `service-traitement` :

```bash
# Compile et crÃ©e le package en ignorant les tests (plus rapide en dev)
mvn clean package -DskipTests
```

Ou, si le projet est configurÃ© en multi-modules, depuis la racine `bugtracker-system` :

```bash
mvn clean install -DskipTests
```

### ğŸš€ Lancement et Tests

Ce service dÃ©pend fortement de **PostgreSQL** et **Kafka**. Il doit donc Ãªtre lancÃ© dans son environnement Docker Compose.

#### 1. **ğŸ‹ Lancer l'environnement complet :**

```bash
# Depuis la racine du projet
docker compose up --build
```

#### 2. **ğŸ“‹ Voir les logs du service :**
Pour voir en temps rÃ©el les messages consommÃ©s depuis Kafka et les requÃªtes SQL.

```bash
docker compose logs -f traitement
```

#### 3. **ğŸ§ª Tester l'API directement :**
Pour vÃ©rifier que l'API REST fonctionne, vous pouvez l'appeler directement sur son port exposÃ©.

```bash
# RÃ©cupÃ©rer tous les bugs
curl http://localhost:8082/api/bugs | jq

# RÃ©cupÃ©rer le bug avec l'ID 1
curl http://localhost:8082/api/bugs/1 | jq
```

---

<div align="center">
  <p>ğŸ”„ <strong>Du chaos des erreurs Ã  l'ordre des donnÃ©es - Le traitement intelligent !</strong> ğŸ§ </p>
</div>